import requests
from bs4 import BeautifulSoup


def fetch_kbs_headlines():
    url = 'https://news.kbs.co.kr/news/pc/main/main.html'
    response = requests.get(url)

    if response.status_code != 200:
        print('KBS í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨:', response.status_code)
        return []

    soup = BeautifulSoup(response.text, 'html.parser')
    headline_list = []

    main_wrapper = soup.find('div', class_='main-news-wrapper')
    if main_wrapper is not None:
        main_title = main_wrapper.find('p', class_='title')
        if main_title:
            title = main_title.get_text(separator=' ', strip=True)
            headline_list.append(title)

    sub_wrapper = soup.find('div', class_='small-sub-news-wrapper')
    if sub_wrapper is not None:
        sub_titles = sub_wrapper.find_all('p', class_='title')
        for tag in sub_titles:
            title = tag.get_text(separator=' ', strip=True)
            headline_list.append(title)

    return headline_list


def fetch_naver_weather():
    url = 'https://search.naver.com/search.naver?query=ë‚ ì”¨'
    response = requests.get(url)

    if response.status_code != 200:
        print('ë‚ ì”¨ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨:', response.status_code)
        return []

    soup = BeautifulSoup(response.text, 'html.parser')
    weather_list = []

    temp_tag = soup.find('div', class_='temperature_text')
    if temp_tag:
        temperature = temp_tag.get_text(strip=True)
        weather_list.append(f'í˜„ì¬ ì˜¨ë„: {temperature}')

    condition_tag = soup.find('span', class_='weather before_slash')
    if condition_tag:
        condition = condition_tag.get_text(strip=True)
        weather_list.append(f'ë‚ ì”¨ ìƒíƒœ: {condition}')

    summary_tags = soup.select('dl.summary_list > div.item_today > span.txt')
    labels = ['ì²´ê° ì˜¨ë„', 'ìŠµë„', 'í’ì†']
    for i, tag in enumerate(summary_tags[:3]):
        weather_list.append(f'{labels[i]}: {tag.get_text(strip=True)}')

    return weather_list


def fetch_naver_popular_stocks():
    url = 'https://finance.naver.com/sise/lastsearch2.naver'
    response = requests.get(url)

    if response.status_code != 200:
        print('ì£¼ì‹ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨:', response.status_code)
        return []

    soup = BeautifulSoup(response.text, 'html.parser')
    stock_list = []

    rows = soup.select('table.type_5 tr')[2:]  # Skip header rows

    for row in rows[:5]:  # ìƒìœ„ 5ê°œë§Œ ê°€ì ¸ì˜¤ê¸°
        cols = row.select('td')
        if len(cols) >= 2:
            name = cols[1].get_text(strip=True)
            price = cols[3].get_text(strip=True)
            stock_list.append(f'{name}: {price}ì›')

    return stock_list


def main():
    while True:
        print('\n--- ì •ë³´ ì„ íƒ ---')
        print('1. KBS í—¤ë“œë¼ì¸ ë‰´ìŠ¤')
        print('2. ë„¤ì´ë²„ ë‚ ì”¨')
        print('3. ë„¤ì´ë²„ ì¸ê¸° ì£¼ì‹')
        print('0. ì¢…ë£Œ')

        choice = input('ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (0~3): ').strip()

        if choice == '1':
            headlines = fetch_kbs_headlines()
            print('\nğŸ“¢ KBS í—¤ë“œë¼ì¸ ë‰´ìŠ¤:')
            for i, title in enumerate(headlines, start=1):
                print(f'{i}. {title}')

        elif choice == '2':
            weather = fetch_naver_weather()
            print('\nğŸŒ¤ï¸ í˜„ì¬ ë‚ ì”¨ ì •ë³´:')
            for item in weather:
                print('-', item)

        elif choice == '3':
            stocks = fetch_naver_popular_stocks()
            print('\nğŸ“ˆ ì¸ê¸° ê²€ìƒ‰ ì£¼ì‹ TOP 5:')
            for i, item in enumerate(stocks, start=1):
                print(f'{i}. {item}')

        elif choice == '0':
            print('í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.')
            break

        else:
            print('ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. 0~3 ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.')


if __name__ == '__main__':
    main()